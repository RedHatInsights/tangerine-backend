---
kind: Template
apiVersion: template.openshift.io/v1
metadata:
  name: tangerine-backend

objects:
# tangerine backend
- kind: Deployment
  apiVersion: apps/v1
  metadata:
    name: tangerine-backend
  spec:
    strategy:
      type: Recreate  # TODO: switch to Rolling
      recreateParams:
        timeoutSeconds: 600
      resources: {}
      activeDeadlineSeconds: 21600
    replicas: 1
    selector:
      matchLabels:
        app: tangerine-backend
    template:
      metadata:
        labels:
          app: tangerine-backend
      spec:
        containers:
          - resources:
              requests:
                memory: 256Mi
                cpu: 250m
              limits:
                memory: 512Mi
                cpu: 500m
            readinessProbe:
              httpGet:
                path: /ping
                port: 5000
              initialDelaySeconds: 5
              periodSeconds: 5
              timeoutSeconds: 1
              successThreshold: 1
              failureThreshold: 3
            livenessProbe:
              httpGet:
                path: /ping
                port: 5000
              initialDelaySeconds: 5
              periodSeconds: 5
              timeoutSeconds: 1
              successThreshold: 1
              failureThreshold: 3
            terminationMessagePath: /dev/termination-log
            name: tangerine-backend
            env:
              - name: DB_USERNAME
                valueFrom:
                  secretKeyRef:
                    name: vector-db
                    key: db.user
              - name: DB_PASSWORD
                valueFrom:
                  secretKeyRef:
                    name: vector-db
                    key: db.password
              - name: DB_NAME
                valueFrom:
                  secretKeyRef:
                    name: vector-db
                    key: db.name
              - name: DB_HOST
                valueFrom:
                  secretKeyRef:
                    name: vector-db
                    key: db.host
              - name: DB_PORT
                valueFrom:
                  secretKeyRef:
                    name: vector-db
                    key: db.port
              - name: LLM_BASE_URL
                value: ${LLM_BASE_URL}
              - name: EMBED_BASE_URL
                value: ${EMBED_BASE_URL}
              - name: LLM_MODEL_NAME
                value: ${LLM_MODEL_NAME}
              - name: EMBED_MODEL_NAME
                value: ${EMBED_MODEL_NAME}
              - name: EMBED_QUERY_PREFIX
                value: ${EMBED_QUERY_PREFIX}
            securityContext:
              capabilities: {}
              privileged: false
            ports:
              - containerPort: 5000
                protocol: TCP
            imagePullPolicy: Always  # TODO: change to "IfNotPresent" when project stabilizes
            terminationMessagePolicy: File
            image: 'quay.io/tangerine/tangerine-backend:latest'
        restartPolicy: Always
        terminationGracePeriodSeconds: 30
        dnsPolicy: ClusterFirst
        securityContext: {}
        schedulerName: default-scheduler

- kind: Service
  apiVersion: v1
  metadata:
    name: tangerine-backend
  spec:
    selector:
      app: tangerine-backend
    ports:
      - name: tangerine-backend
        protocol: TCP
        port: 5000
        targetPort: 5000

parameters:
  - name: LLM_BASE_URL
    value: http://vllm.llm-hosting.svc.cluster.local:8000/v1
  - name: EMBED_BASE_URL
    value: http://text-embeddings-inference:3000/v1
  - name: LLM_MODEL_NAME
    value: mistralai/Mistral-7B-Instruct-v0.2
  - name: EMBED_MODEL_NAME
    value: Snowflake/snowflake-arctic-embed-m-long
  - name: EMBED_QUERY_PREFIX
    value: "Represent this sentence for searching relevant passages"
  - name: LLM_TEMPERATURE
    value: "0.3"
